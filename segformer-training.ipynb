{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f90886bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import gc\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from typing import List, Tuple, Optional, Any, Dict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from transformers import SegformerImageProcessor, SegformerForSemanticSegmentation\n",
    "from evaluate import load\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "from torchmetrics.functional import dice\n",
    "import wandb\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from operator import itemgetter\n",
    "from PIL import Image\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "import time\n",
    "import copy\n",
    "from collections import defaultdict\n",
    "\n",
    "from colorama import Fore, Back, Style\n",
    "c_  = Fore.GREEN\n",
    "sr_ = Style.RESET_ALL\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799698cf",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0a9e7cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    seed          = 101\n",
    "    debug         = False\n",
    "    exp_name      = 'cityscapes'\n",
    "    comment       = 'segformer-b5-cityscapes-1024x1024-ep=5'\n",
    "    model_name    = 'segformer'\n",
    "    train_bs      = 1\n",
    "    valid_bs      = 1\n",
    "    image_size    = [1024, 1024]\n",
    "    epochs        = 5\n",
    "    lr            = 2e-3\n",
    "    scheduler     = 'CosineAnnealingLR'\n",
    "    min_lr        = 1e-6\n",
    "    T_max         = int(30000/train_bs*epochs) + 50\n",
    "    T_0           = 25\n",
    "    warmup_epochs = 0\n",
    "    weight_decay  = 1e-6\n",
    "    n_fold        = 5\n",
    "    num_classes   = 19\n",
    "    device        = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f41b26",
   "metadata": {},
   "source": [
    "## Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "70ecbf58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- SEEDING DONE ---\n"
     ]
    }
   ],
   "source": [
    "def set_seed(seed: int = 42):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    print('--- SEEDING DONE ---')\n",
    "\n",
    "set_seed(CFG.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e040edc",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5a65f035",
   "metadata": {},
   "outputs": [],
   "source": [
    "Label = namedtuple( 'Label' , [\n",
    "\n",
    "    'name'        , # The identifier of this label, e.g. 'car', 'person', ... .\n",
    "                    # We use them to uniquely name a class\n",
    "\n",
    "    'id'          , # An integer ID that is associated with this label.\n",
    "                    # The IDs are used to represent the label in ground truth images\n",
    "                    # An ID of -1 means that this label does not have an ID and thus\n",
    "                    # is ignored when creating ground truth images (e.g. license plate).\n",
    "                    # Do not modify these IDs, since exactly these IDs are expected by the\n",
    "                    # evaluation server.\n",
    "\n",
    "    'trainId'     , # Feel free to modify these IDs as suitable for your method. Then create\n",
    "                    # ground truth images with train IDs, using the tools provided in the\n",
    "                    # 'preparation' folder. However, make sure to validate or submit results\n",
    "                    # to our evaluation server using the regular IDs above!\n",
    "                    # For trainIds, multiple labels might have the same ID. Then, these labels\n",
    "                    # are mapped to the same class in the ground truth images. For the inverse\n",
    "                    # mapping, we use the label that is defined first in the list below.\n",
    "                    # For example, mapping all void-type classes to the same ID in training,\n",
    "                    # might make sense for some approaches.\n",
    "                    # Max value is 255!\n",
    "\n",
    "    'category'    , # The name of the category that this label belongs to\n",
    "\n",
    "    'categoryId'  , # The ID of this category. Used to create ground truth images\n",
    "                    # on category level.\n",
    "\n",
    "    'hasInstances', # Whether this label distinguishes between single instances or not\n",
    "\n",
    "    'ignoreInEval', # Whether pixels having this class as ground truth label are ignored\n",
    "                    # during evaluations or not\n",
    "\n",
    "    'color'       , # The color of this label\n",
    "    ] )\n",
    "\n",
    "\n",
    "labels = [\n",
    "    #       name                     id    trainId   category            catId     hasInstances   ignoreInEval   color\n",
    "    Label(  'unlabeled'            ,  0 ,      255 , 'void'            , 0       , False        , True         , (  0,  0,  0) ),\n",
    "    Label(  'ego vehicle'          ,  1 ,      255 , 'void'            , 0       , False        , True         , (  0,  0,  0) ),\n",
    "    Label(  'rectification border' ,  2 ,      255 , 'void'            , 0       , False        , True         , (  0,  0,  0) ),\n",
    "    Label(  'out of roi'           ,  3 ,      255 , 'void'            , 0       , False        , True         , (  0,  0,  0) ),\n",
    "    Label(  'static'               ,  4 ,      255 , 'void'            , 0       , False        , True         , (  0,  0,  0) ),\n",
    "    Label(  'dynamic'              ,  5 ,      255 , 'void'            , 0       , False        , True         , (111, 74,  0) ),\n",
    "    Label(  'ground'               ,  6 ,      255 , 'void'            , 0       , False        , True         , ( 81,  0, 81) ),\n",
    "    Label(  'road'                 ,  7 ,        0 , 'flat'            , 1       , False        , False        , (128, 64,128) ),\n",
    "    Label(  'sidewalk'             ,  8 ,        1 , 'flat'            , 1       , False        , False        , (244, 35,232) ),\n",
    "    Label(  'parking'              ,  9 ,      255 , 'flat'            , 1       , False        , True         , (250,170,160) ),\n",
    "    Label(  'rail track'           , 10 ,      255 , 'flat'            , 1       , False        , True         , (230,150,140) ),\n",
    "    Label(  'building'             , 11 ,        2 , 'construction'    , 2       , False        , False        , ( 70, 70, 70) ),\n",
    "    Label(  'wall'                 , 12 ,        3 , 'construction'    , 2       , False        , False        , (102,102,156) ),\n",
    "    Label(  'fence'                , 13 ,        4 , 'construction'    , 2       , False        , False        , (190,153,153) ),\n",
    "    Label(  'guard rail'           , 14 ,      255 , 'construction'    , 2       , False        , True         , (180,165,180) ),\n",
    "    Label(  'bridge'               , 15 ,      255 , 'construction'    , 2       , False        , True         , (150,100,100) ),\n",
    "    Label(  'tunnel'               , 16 ,      255 , 'construction'    , 2       , False        , True         , (150,120, 90) ),\n",
    "    Label(  'pole'                 , 17 ,        5 , 'object'          , 3       , False        , False        , (153,153,153) ),\n",
    "    Label(  'polegroup'            , 18 ,      255 , 'object'          , 3       , False        , True         , (153,153,153) ),\n",
    "    Label(  'traffic light'        , 19 ,        6 , 'object'          , 3       , False        , False        , (250,170, 30) ),\n",
    "    Label(  'traffic sign'         , 20 ,        7 , 'object'          , 3       , False        , False        , (220,220,  0) ),\n",
    "    Label(  'vegetation'           , 21 ,        8 , 'nature'          , 4       , False        , False        , (107,142, 35) ),\n",
    "    Label(  'terrain'              , 22 ,        9 , 'nature'          , 4       , False        , False        , (152,251,152) ),\n",
    "    Label(  'sky'                  , 23 ,       10 , 'sky'             , 5       , False        , False        , ( 70,130,180) ),\n",
    "    Label(  'person'               , 24 ,       11 , 'human'           , 6       , True         , False        , (220, 20, 60) ),\n",
    "    Label(  'rider'                , 25 ,       12 , 'human'           , 6       , True         , False        , (255,  0,  0) ),\n",
    "    Label(  'car'                  , 26 ,       13 , 'vehicle'         , 7       , True         , False        , (  0,  0,142) ),\n",
    "    Label(  'truck'                , 27 ,       14 , 'vehicle'         , 7       , True         , False        , (  0,  0, 70) ),\n",
    "    Label(  'bus'                  , 28 ,       15 , 'vehicle'         , 7       , True         , False        , (  0, 60,100) ),\n",
    "    Label(  'caravan'              , 29 ,      255 , 'vehicle'         , 7       , True         , True         , (  0,  0, 90) ),\n",
    "    Label(  'trailer'              , 30 ,      255 , 'vehicle'         , 7       , True         , True         , (  0,  0,110) ),\n",
    "    Label(  'train'                , 31 ,       16 , 'vehicle'         , 7       , True         , False        , (  0, 80,100) ),\n",
    "    Label(  'motorcycle'           , 32 ,       17 , 'vehicle'         , 7       , True         , False        , (  0,  0,230) ),\n",
    "    Label(  'bicycle'              , 33 ,       18 , 'vehicle'         , 7       , True         , False        , (119, 11, 32) ),\n",
    "    Label(  'license plate'        , -1 ,       -1 , 'vehicle'         , 7       , False        , True         , (  0,  0,142) ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bd297b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CityScapesDataset(data.Dataset):\n",
    "    def __init__(self, image_paths: List[str], mask_paths: List[str], stage: str = \"train\", image_size: int = 1024) -> None:\n",
    "        super(CityScapesDataset, self).__init__()\n",
    "        self.image_paths = image_paths\n",
    "        self.mask_paths = mask_paths\n",
    "        self.image_size = image_size\n",
    "\n",
    "        if stage == \"train\":\n",
    "            self.transforms = A.Compose([\n",
    "                A.augmentations.Resize(height=self.image_size, width=self.image_size, interpolation=0),\n",
    "                A.augmentations.Rotate(limit=90, p=0.5),\n",
    "                A.augmentations.HorizontalFlip(p=0.5),\n",
    "#                 A.augmentations.VerticalFlip(p=0.5),\n",
    "                A.augmentations.transforms.ColorJitter(p=0.5),\n",
    "                A.Normalize(),\n",
    "                A.pytorch.ToTensorV2(),\n",
    "            ])\n",
    "\n",
    "\n",
    "        else:\n",
    "            self.transforms = A.Compose([\n",
    "                A.Resize(height=self.image_size, width=self.image_size, interpolation=0),\n",
    "                A.Normalize(),\n",
    "                ToTensorV2()\n",
    "            ])\n",
    "\n",
    "        self.target_train_ids = []\n",
    "        self.target_ids = []\n",
    "        self.target_colors = []\n",
    "        self.target_labels = []\n",
    "\n",
    "        for label in labels:\n",
    "            if label.trainId != 255 and label.trainId != -1:\n",
    "                self.target_colors.append(label.color)\n",
    "                self.target_labels.append(label.name)\n",
    "                self.target_train_ids.append(label.trainId)\n",
    "                self.target_ids.append(label.id)\n",
    "\n",
    "        self.cmap = dict(zip(self.target_train_ids, self.target_colors))\n",
    "        self.idmap = dict(zip(self.target_ids, self.target_train_ids))\n",
    "\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        image = np.array(Image.open(self.image_paths[idx]))\n",
    "        mask = np.array(Image.open(self.mask_paths[idx]))\n",
    "\n",
    "        transformed = self.transforms(image=image, mask=mask)\n",
    "\n",
    "        image, mask = transformed['image'], transformed['mask']\n",
    "\n",
    "        unique = pd.Series(mask.reshape(-1)).unique()\n",
    "\n",
    "        for ele in unique:\n",
    "            if ele not in self.idmap.keys():\n",
    "                mask = mask.where(mask != ele, 255)\n",
    "\n",
    "        unique = pd.Series(mask.reshape(-1)).unique()\n",
    "        # print(unoq)\n",
    "        for k, v in self.idmap.items():\n",
    "            mask = mask.where(mask != k, v)\n",
    "\n",
    "        new_mask = torch.stack([mask]*3, axis=-1)\n",
    "        new_mask.shape\n",
    "\n",
    "        for k, v in self.cmap.items():\n",
    "            # print(k, v)\n",
    "            new_mask = new_mask.where(new_mask != k, torch.LongTensor(v))\n",
    "\n",
    "        return {\n",
    "            'image': image.clone(),\n",
    "            'mask': mask,\n",
    "            'colored': new_mask,\n",
    "            'instance': np.array(Image.open(self.mask_paths[idx]))\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f15b8d",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fdc9448d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataloader():\n",
    "    train_dataset = CityScapesDataset(\n",
    "        image_paths=sorted(list(glob('./data/leftImg8bit_trainvaltest/leftImg8bit/train/*/*.png'))),\n",
    "        mask_paths=sorted(list(glob('./data/gtFine_trainvaltest/gtFine/train/*/*_gtFine_labelIds.png'))),\n",
    "        stage=\"train\",\n",
    "        image_size=CFG.image_size[0]\n",
    "    )\n",
    "    \n",
    "    valid_dataset = CityScapesDataset(\n",
    "        image_paths=sorted(list(glob('./data/leftImg8bit_trainvaltest/leftImg8bit/val/*/*.png'))),\n",
    "        mask_paths=sorted(list(glob('./data/gtFine_trainvaltest/gtFine/val/*/*_gtFine_labelIds.png'))),\n",
    "        stage=\"train\",\n",
    "        image_size=CFG.image_size[0]\n",
    "    )\n",
    "    \n",
    "    train_loader = data.DataLoader(train_dataset, batch_size=CFG.train_bs, shuffle=True, pin_memory=True)\n",
    "    valid_loader = data.DataLoader(valid_dataset, batch_size=CFG.valid_bs, shuffle=False, pin_memory=True) \n",
    "    \n",
    "    return train_loader, valid_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "55ec1d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, valid_loader = prepare_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a3c52717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x2fb3c33d0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f2507ca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': torch.Size([1, 3, 1024, 1024]),\n",
       " 'mask': torch.Size([1, 1024, 1024]),\n",
       " 'colored': torch.Size([1, 1024, 1024, 3]),\n",
       " 'instance': torch.Size([1, 1024, 2048])}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(train_loader))\n",
    "{k:v.shape for k, v in batch.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3ceaf972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': torch.Size([1, 3, 1024, 1024]),\n",
       " 'mask': torch.Size([1, 1024, 1024]),\n",
       " 'colored': torch.Size([1, 1024, 1024, 3]),\n",
       " 'instance': torch.Size([1, 1024, 2048])}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(valid_loader))\n",
    "{k:v.shape for k, v in batch.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dd90675b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36553"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d3f3c6",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8f4ae430",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegmentationModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SegmentationModel, self).__init__()\n",
    "        self.model = SegformerForSemanticSegmentation.from_pretrained(\n",
    "            \"nvidia/segformer-b5-finetuned-cityscapes-1024-1024\",\n",
    "            ignore_mismatched_sizes=True,\n",
    "        )\n",
    "\n",
    "    def forward(self, batch: Dict[str, torch.Tensor]) -> torch.Tensor:\n",
    "        outputs = self.model(pixel_values=batch['image'])\n",
    "\n",
    "        upsampled_logits = F.interpolate(\n",
    "            outputs.logits,\n",
    "            size=batch['mask'].shape[-2:],\n",
    "            mode=\"bilinear\",\n",
    "            align_corners=False\n",
    "        )\n",
    "\n",
    "        return upsampled_logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c749ab",
   "metadata": {},
   "source": [
    "## Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5fb4596c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, optimizer, scheduler, loss_fn, loader):\n",
    "    model.train()\n",
    "    \n",
    "    dataset_size = 0\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    pbar = tqdm(enumerate(loader), total=len(loader), desc='Train ')\n",
    "    for step, batch in pbar:\n",
    "        images = batch['image'].to(CFG.device, dtype=torch.float32)\n",
    "        mask = batch['mask'].to(CFG.device, dtype=torch.float32)\n",
    "        \n",
    "        batch_size = images.size(0)\n",
    "        \n",
    "        y_pred = model(images)\n",
    "        loss = loss_fn(y_pred=y_pred, y_true=mask)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "        \n",
    "        running_loss += (loss.item() * batch_size)\n",
    "        dataset_size += batch_size\n",
    "        \n",
    "        epoch_loss = running_loss / dataset_size\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        pbar.set_postfix(\n",
    "            train_loss=f'{epoch_loss:.3f}',\n",
    "            lr=f'{current_lr:.3f}'\n",
    "        )\n",
    "        gc.collect()\n",
    "    \n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7acacac",
   "metadata": {},
   "source": [
    "## Validation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "be9776c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def valid_one_epoch(model, loss_fn, loader):\n",
    "    model.eval()\n",
    "    \n",
    "    dataset_size = 0\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    pbar = tqdm(enumerate(loader), total=len(loader), desc='Valid ')\n",
    "    for step, batch in pbar:\n",
    "        images = batch['images'].to(CFG.device, dtype=torch.float32)\n",
    "        masks = batch['masks'].to(CFG.device, dtype=torch.float32)\n",
    "        \n",
    "        batch_size = images.size(0)\n",
    "        \n",
    "        y_pred = model(images)\n",
    "        loss = loss_fn(y_pred=y_pred, y_true=masks)\n",
    "        \n",
    "        running_loss += (loss.item() * batch_size)\n",
    "        dataset_size += batch_size\n",
    "        \n",
    "        epoch_loss = running_loss / dataset_size\n",
    "        \n",
    "        pbar.set_postfix(\n",
    "            valid_loss=f'{epoch_loss:.3f}',\n",
    "        )\n",
    "        \n",
    "        gc.collect()\n",
    "    \n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "91c24ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(model, optimizer, scheduler, device, num_epochs):\n",
    "    # To automatically log gradients\n",
    "    wandb.watch(model, log_freq=100)\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        print(\"cuda: {}\\n\".format(torch.cuda.get_device_name()))\n",
    "    \n",
    "    start = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_dice      = -np.inf\n",
    "    best_epoch     = -1\n",
    "    history = defaultdict(list)\n",
    "    \n",
    "    for epoch in range(1, num_epochs + 1): \n",
    "        gc.collect()\n",
    "        print(f'Epoch {epoch}/{num_epochs}', end='')\n",
    "        train_loss = train_one_epoch(model, optimizer, scheduler, \n",
    "                                           dataloader=train_loader, \n",
    "                                           device=CFG.device, epoch=epoch)\n",
    "        \n",
    "        val_loss, val_scores = valid_one_epoch(model, valid_loader, \n",
    "                                                 device=CFG.device, \n",
    "                                                 epoch=epoch)\n",
    "        val_dice, val_jaccard = val_scores\n",
    "    \n",
    "        history['Train Loss'].append(train_loss)\n",
    "        history['Valid Loss'].append(val_loss)\n",
    "        history['Valid Dice'].append(val_dice)\n",
    "        history['Valid Jaccard'].append(val_jaccard)\n",
    "        \n",
    "        # Log the metrics\n",
    "        wandb.log({\"Train Loss\": train_loss, \n",
    "                   \"Valid Loss\": val_loss,\n",
    "                   \"Valid Dice\": val_dice,\n",
    "                   \"Valid Jaccard\": val_jaccard,\n",
    "                   \"LR\":scheduler.get_last_lr()[0]})\n",
    "        \n",
    "        print(f'Valid Dice: {val_dice:0.4f} | Valid Jaccard: {val_jaccard:0.4f}')\n",
    "        \n",
    "        # deep copy the model\n",
    "        if val_dice >= best_dice:\n",
    "            print(f\"{c_}Valid Score Improved ({best_dice:0.4f} ---> {val_dice:0.4f})\")\n",
    "            best_dice    = val_dice\n",
    "            best_jaccard = val_jaccard\n",
    "            best_epoch   = epoch\n",
    "            run.summary[\"Best Dice\"]    = best_dice\n",
    "            run.summary[\"Best Jaccard\"] = best_jaccard\n",
    "            run.summary[\"Best Epoch\"]   = best_epoch\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            PATH = f\"best_epoch-{fold:02d}.bin\"\n",
    "            torch.save(model.state_dict(), PATH)\n",
    "            # Save a model file from the current directory\n",
    "            wandb.save(PATH)\n",
    "            print(f\"Model Saved{sr_}\")\n",
    "            \n",
    "        last_model_wts = copy.deepcopy(model.state_dict())\n",
    "        PATH = f\"last_epoch-{fold:02d}.bin\"\n",
    "        torch.save(model.state_dict(), PATH)\n",
    "            \n",
    "        print(); print()\n",
    "    \n",
    "    end = time.time()\n",
    "    time_elapsed = end - start\n",
    "    print('Training complete in {:.0f}h {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n",
    "    print(\"Best Score: {:.4f}\".format(best_jaccard))\n",
    "    \n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "376c279b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.has_mps else \"cpu\")\n",
    "model = SegmentationModel().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7f8751f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:5zxepaaa) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "237f2b9aee86407185c5db88a4730f7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">iconic-water-5</strong> at: <a href='https://wandb.ai/aaparajit02/prism-stuff/runs/5zxepaaa' target=\"_blank\">https://wandb.ai/aaparajit02/prism-stuff/runs/5zxepaaa</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230322_131412-5zxepaaa/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:5zxepaaa). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ac9a8f6341144beba25960dc4778253",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016751231933327896, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/aneeshaparajit/Desktop/new workspace/prism-stuff/wandb/run-20230322_132315-71vvakfl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/aaparajit02/prism-stuff/runs/71vvakfl' target=\"_blank\">warm-planet-6</a></strong> to <a href='https://wandb.ai/aaparajit02/prism-stuff' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/aaparajit02/prism-stuff' target=\"_blank\">https://wandb.ai/aaparajit02/prism-stuff</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/aaparajit02/prism-stuff/runs/71vvakfl' target=\"_blank\">https://wandb.ai/aaparajit02/prism-stuff/runs/71vvakfl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1 </span>wandb.init()                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>3 run_training(model, optimizer, scheduler, device, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">5</span>)                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">run_training</span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> epoch <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">range</span>(<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>, num_epochs + <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>):                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">15 │   │   </span>gc.collect()                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">16 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">print</span>(<span style=\"color: #808000; text-decoration-color: #808000\">f'Epoch {</span>epoch<span style=\"color: #808000; text-decoration-color: #808000\">}/{</span>num_epochs<span style=\"color: #808000; text-decoration-color: #808000\">}'</span>, end=<span style=\"color: #808000; text-decoration-color: #808000\">''</span>)                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>17 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>train_loss = train_one_epoch(model, optimizer, scheduler,                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18 │   │   │   │   │   │   │   │   │   │      </span>dataloader=train_loader,                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">19 │   │   │   │   │   │   │   │   │   │      </span>device=CFG.device, epoch=epoch)                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">20 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">TypeError: </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">train_one_epoch</span><span style=\"font-weight: bold\">()</span> got an unexpected keyword argument <span style=\"color: #008000; text-decoration-color: #008000\">'dataloader'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1 \u001b[0mwandb.init()                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m3 run_training(model, optimizer, scheduler, device, \u001b[94m5\u001b[0m)                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m4 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92mrun_training\u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m14 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mfor\u001b[0m epoch \u001b[95min\u001b[0m \u001b[96mrange\u001b[0m(\u001b[94m1\u001b[0m, num_epochs + \u001b[94m1\u001b[0m):                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m15 \u001b[0m\u001b[2m│   │   \u001b[0mgc.collect()                                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m16 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mprint\u001b[0m(\u001b[33mf\u001b[0m\u001b[33m'\u001b[0m\u001b[33mEpoch \u001b[0m\u001b[33m{\u001b[0mepoch\u001b[33m}\u001b[0m\u001b[33m/\u001b[0m\u001b[33m{\u001b[0mnum_epochs\u001b[33m}\u001b[0m\u001b[33m'\u001b[0m, end=\u001b[33m'\u001b[0m\u001b[33m'\u001b[0m)                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m17 \u001b[2m│   │   \u001b[0mtrain_loss = train_one_epoch(model, optimizer, scheduler,                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m18 \u001b[0m\u001b[2m│   │   │   │   │   │   │   │   │   │      \u001b[0mdataloader=train_loader,                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m19 \u001b[0m\u001b[2m│   │   │   │   │   │   │   │   │   │      \u001b[0mdevice=CFG.device, epoch=epoch)                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m20 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mTypeError: \u001b[0m\u001b[1;35mtrain_one_epoch\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m got an unexpected keyword argument \u001b[32m'dataloader'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init()\n",
    "\n",
    "run_training(model, optimizer, scheduler, device, 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (torch)",
   "language": "python",
   "name": "torch-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
